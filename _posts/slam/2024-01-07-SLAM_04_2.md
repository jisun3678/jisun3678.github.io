---
layout: post
image: /assets/images/blog/post-5.jpg
title: "SLAM 4-2강 (Graph-based SLAM with Landmarks) 요약"
categories:
    - SLAM
tags:
    - SLAM
toc: true
toc_sticky: true
comments: true
---

## 0. 오늘의 목표  

- Landmark를 포함한 그래프 구조 이해  
- Landmark Observation 방식 분석  
- Landmark를 활용한 로봇 위치 추정 방법  

---

## 1. 강의 및 자료 소개  

이번 강의에서는 Landmark를 포함한 Graph-based SLAM에 대해 다룹니다.  
참고 자료:  
- [Graph-based SLAM with Landmarks (Cyrill Stachniss)](https://youtu.be/mZBdPgBtrCM)  
- [SLAM DUNK Season 2 - Graph-Based SLAM Using Pose Graph](https://youtu.be/I8wCohCAS60)  
- [강의 자료 PDF](https://drive.google.com/file/d/1JQkHD7vFHAaoGlLp2wK7h4uipHIIxYM9/view?usp=sharing)  

---

## 2. Landmark를 포함한 그래프 구조  

Graph-based SLAM은 Pose Graph에서 로봇의 위치를 Node로 표현하고, Pose 간의 관계를 Edge로 표현합니다. 이번 강의에서는 여기에 **Landmark**를 추가하여 환경 정보를 그래프에 포함시키는 방법을 다룹니다.  

### Landmark의 역할
- Landmark는 로봇 주변의 환경 정보(특징점)를 나타냅니다.  
- Node로 포함되며, 위치 정보만을 저장합니다 (예: $(x, y)$).  

### 구조의 차이
Pose Graph와 달리 Landmark를 포함한 그래프는 다음과 같이 구성됩니다:  
- **Node**: 로봇의 Pose 및 Landmark의 위치.  
- **Edge**: 
  - Pose 간의 Odometry 정보.  
  - Pose와 Landmark 간의 Observation 정보.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/152905242-fe413fee-3e2f-474d-93e9-bc157e616824.png" width="550"></p>  

---

## 3. Landmark Observation  

### Observation 유형
1. **$(x, y)$ Observation**: Landmark의 좌표 정보를 포함.  
2. **Bearing Only Observation**: Landmark와의 방향 정보만 포함.  

#### $(x, y)$ Observation  
로봇과 Landmark 간의 위치 관계를 나타내며, 다음과 같은 수식으로 표현됩니다:  
$$
\hat{z}_{ij} = R_i^T (x_j - t_i)
$$  
- $R_i$: 로봇 Pose의 Rotation Matrix.  
- $t_i$: 로봇 Pose의 Translation 값.  
- $x_j$: Landmark의 위치.  

오차(Error)는 다음과 같이 계산됩니다:  
$$
e_{ij} = z_{ij} - \hat{z}_{ij}
$$  

#### Bearing Only Observation  
Landmark와의 방향 관계만 표현하며, 아래와 같은 수식으로 나타냅니다:  
$$
\hat{\theta}_{ij} = \text{atan2}((x_j - t_i).y, (x_j - t_i).x)
$$  
- $(x_j - t_i).x$, $(x_j - t_i).y$: Landmark와 로봇 간의 $x$ 및 $y$ 차이.  

오차는 다음과 같이 계산됩니다:  
$$
e_{ij} = z_{ij} - \hat{\theta}_{ij}
$$  

---

## 4. Landmark를 활용한 로봇 위치 추정  

### 관측치로부터 로봇 위치 추정
Landmark Observation을 통해 로봇 위치를 추정할 때, 하나의 Observation만으로는 정확한 위치를 파악하기 어렵습니다:  
- **$(x, y)$ Observation**: Landmark 주변 원형으로 추정 가능.  
- **Bearing Only Observation**: Landmark를 기준으로 방사형으로 추정 가능.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/152939065-5cf7da7f-f332-439d-b1b3-6dd15ed89580.png" width="600"></p>  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/152939487-4a70150d-d3d6-4caa-88db-27577fddefba.png" width="550"></p>  

### Full Rank 조건
정확한 로봇 위치를 추정하려면 시스템이 Full Rank를 가져야 합니다. 이를 위해 Gauss-Newton 최적화에 Damping Factor를 추가하여 시스템을 안정화합니다:  
$$
(H + \lambda I) \Delta x = -b
$$  
- $\lambda$: Damping Factor.  

이 방법은 Levenberg-Marquardt 알고리즘으로 확장됩니다.  

---

## 5. Levenberg-Marquardt 알고리즘  

Levenberg-Marquardt는 Gauss-Newton과 Steepest Descent를 결합한 방식으로, 최적화의 안정성과 효율성을 모두 제공합니다.  

### 알고리즘 흐름
1. 초기값 설정.  
2. $H$와 $b$ 계산 후 Damping Factor 적용.  
3. 업데이트된 $\Delta x$로 Pose와 Landmark 위치 갱신.  
4. 수렴할 때까지 반복.  

<p align="center"><img src="https://user-images.githubusercontent.com/41863759/152942933-e4d71a2e-0047-4086-9b3f-157d54ebe579.png" width="550"></p>  

---

## 6. 응용: Bundle Adjustment  

Levenberg-Marquardt는 Visual SLAM에서의 Bundle Adjustment에 자주 사용됩니다:  
- 다양한 뷰포인트에서 촬영한 이미지와 환경 정보를 조합.  
- 카메라의 Pose와 3D Feature Point의 위치를 추정.  
- Reprojection Error를 최소화하는 방향으로 최적화.  

---

Landmark를 포함한 Graph-based SLAM은 로봇과 환경 간의 관계를 명확히 하고, 이를 통해 더 정교한 맵핑과 로봇 위치 추정을 가능하게 합니다.  
